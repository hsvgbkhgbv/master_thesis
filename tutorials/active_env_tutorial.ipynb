{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\vegardso\\\\PycharmProjects\\\\master_thesis')\n",
    "import numpy as np\n",
    "from active_env.envs.active_network_env import ActiveEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial showing the functionality of `ActiveEnv`\n",
    "This notebook gives an introduction to the class `ActiveEnv`. The class follows the structure of a general `gym` environment, and can be used for reinforcement algorithms available in [stable-baselines](https://github.com/hill-a/stable-baselines).\n",
    "\n",
    "A general gym environment has the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.34 s ± 131 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ENV = ActiveEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "ENV = ActiveEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 ms ± 682 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit env = copy.deepcopy(ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "class FooEnv(gym.Env):\n",
    "  metadata = {'render.modes': ['human']}\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  def step(self, action):\n",
    "    pass\n",
    "  def reset(self):\n",
    "    pass\n",
    "  def render(self, mode='human', close=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ActiveEnv` does not have a `render()` method implemented. This is typically used to visualise a game or some other environment that can be animated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief description of the motivation\n",
    "\n",
    "The agent is allowed to modify the power consumption at nodes in a distribution system with high peak demand and high production from solar power. The goal of the agent is to reduce the number of current and voltage violations in the grid by increasing/ decreasing the consumption at appropriate times. The increase/decrease in power consumption is intended to be a simplified program for demand response that exploits the residential flexibility in the grid. \n",
    "\n",
    "Currently, the implementation is based on a significant simplification:\n",
    "- <b>Constant flexibility:</b>\n",
    "The flexibility is assumed to be constant. If the agent increases the consumption in one hour, it has no consequences for the future flexibility in the system. This is not realistic, as increasing the consumption corresponds to turning on electrical equipment, and that equipment can't be turned on again later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic functionality - parameters\n",
    "`ActiveEnv` has several parameters that determine the state space, actions, rewards etc. What the specific parameters do is described later in this notebook. The parameters are given as an attribute `env.params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_length': 200,\n",
       " 'reward_terms': ['voltage', 'current', 'imbalance', 'activation'],\n",
       " 'voltage_weight': 1,\n",
       " 'current_weight': 0.01,\n",
       " 'imbalance_weight': 1e-05,\n",
       " 'activation_weight': 0.1,\n",
       " 'forecast_horizon': 4,\n",
       " 'flexibility': 0.1,\n",
       " 'solar_scale': 0.8,\n",
       " 'demand_scale': 10,\n",
       " 'state_space': ['sun', 'demand', 'bus', 'imbalance'],\n",
       " 'v_upper': 1.05,\n",
       " 'v_lower': 0.95,\n",
       " 'i_upper': 90,\n",
       " 'demand_std': 0.03,\n",
       " 'solar_std': 0.03,\n",
       " 'total_imbalance': False,\n",
       " 'reactive_power': True,\n",
       " 'imbalance_change': False,\n",
       " 'one_action': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = ActiveEnv()\n",
    "env.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the parameters by calling the `set_parameters` method, where we input a dictionary with the parameters we want to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_length': 100,\n",
       " 'reward_terms': ['voltage'],\n",
       " 'voltage_weight': 1,\n",
       " 'current_weight': 0.01,\n",
       " 'imbalance_weight': 1e-05,\n",
       " 'activation_weight': 0.1,\n",
       " 'forecast_horizon': 4,\n",
       " 'flexibility': 0.1,\n",
       " 'solar_scale': 0.8,\n",
       " 'demand_scale': 10,\n",
       " 'state_space': ['sun', 'demand', 'bus', 'imbalance'],\n",
       " 'v_upper': 1.05,\n",
       " 'v_lower': 0.95,\n",
       " 'i_upper': 90,\n",
       " 'demand_std': 0.03,\n",
       " 'solar_std': 0.03,\n",
       " 'total_imbalance': False,\n",
       " 'reactive_power': True,\n",
       " 'imbalance_change': False,\n",
       " 'one_action': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.set_parameters({'episode_length':100,\n",
    "                  'reward_terms':['voltage']})\n",
    "env.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters will affect the size of the state space and action space. By changing those, the state space is automatically updated. Let's change the forecast horizon which determines the length of the forecasts (in hours).\n",
    "\n",
    "First we can see the state space by default consists of 86 variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(86,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the forecast_horizon to 24 hours increases the state space to 126 variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(126,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.set_parameters({'forecast_horizon':24})\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power system\n",
    "<img src= \"figures\\cigre_network_mv_der.png\" style=width:600px;height:600px;>\n",
    "\n",
    "The electrical power grid used is constructed by the International Council on Large Electric Systems (CIGRE). There is wind power connected to bus bar 7 in the figure above, but this is for simplicity assumed to be solar. In other words, all power production from renewable sources in this net follows solar irradiance in this net. The environment can also be given another `pandapower` network.\n",
    "\n",
    "The network is an attribute in the `ActiveEnv` class:\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This pandapower network includes the following parameter tables:\n",
       "   - bus (15 elements)\n",
       "   - load (18 elements)\n",
       "   - sgen (9 elements)\n",
       "   - switch (8 elements)\n",
       "   - ext_grid (1 element)\n",
       "   - line (15 elements)\n",
       "   - trafo (2 elements)\n",
       "   - bus_geodata (15 elements)\n",
       " and the following results tables:\n",
       "   - res_bus (15 elements)\n",
       "   - res_line (15 elements)\n",
       "   - res_trafo (2 elements)\n",
       "   - res_ext_grid (1 element)\n",
       "   - res_load (18 elements)\n",
       "   - res_sgen (9 elements)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = ActiveEnv(seed=3)\n",
    "net = env.powergrid\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandapower` stores information in Pandas DataFrames, and there is a table for each of the listed elements above. For instance, the load table  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>bus</th>\n",
       "      <th>p_mw</th>\n",
       "      <th>q_mvar</th>\n",
       "      <th>const_z_percent</th>\n",
       "      <th>const_i_percent</th>\n",
       "      <th>sn_mva</th>\n",
       "      <th>scaling</th>\n",
       "      <th>in_service</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Load R1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.99400</td>\n",
       "      <td>3.044662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Load R3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.27645</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Load R4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.43165</td>\n",
       "      <td>0.108182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Load R5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.72750</td>\n",
       "      <td>0.182329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Load R6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54805</td>\n",
       "      <td>0.137354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Load R8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.58685</td>\n",
       "      <td>0.147078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Load R10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.47530</td>\n",
       "      <td>0.119121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Load R11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.32980</td>\n",
       "      <td>0.082656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Load R12</td>\n",
       "      <td>12</td>\n",
       "      <td>14.99400</td>\n",
       "      <td>3.044662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Load R14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.20855</td>\n",
       "      <td>0.052268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Load CI1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.84500</td>\n",
       "      <td>1.592474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Load CI3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.22525</td>\n",
       "      <td>0.139597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Load CI7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.07650</td>\n",
       "      <td>0.047410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Load CI9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.57375</td>\n",
       "      <td>0.355578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Load CI10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.06800</td>\n",
       "      <td>0.042143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Load CI12</td>\n",
       "      <td>12</td>\n",
       "      <td>5.01600</td>\n",
       "      <td>1.648679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Load CI13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.03400</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Load CI14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.33150</td>\n",
       "      <td>0.205445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  bus      p_mw    q_mvar  const_z_percent  const_i_percent  \\\n",
       "0     Load R1    1  14.99400  3.044662              0.0              0.0   \n",
       "1     Load R3    3   0.27645  0.069285              0.0              0.0   \n",
       "2     Load R4    4   0.43165  0.108182              0.0              0.0   \n",
       "3     Load R5    5   0.72750  0.182329              0.0              0.0   \n",
       "4     Load R6    6   0.54805  0.137354              0.0              0.0   \n",
       "5     Load R8    8   0.58685  0.147078              0.0              0.0   \n",
       "6    Load R10   10   0.47530  0.119121              0.0              0.0   \n",
       "7    Load R11   11   0.32980  0.082656              0.0              0.0   \n",
       "8    Load R12   12  14.99400  3.044662              0.0              0.0   \n",
       "9    Load R14   14   0.20855  0.052268              0.0              0.0   \n",
       "10   Load CI1    1   4.84500  1.592474              0.0              0.0   \n",
       "11   Load CI3    3   0.22525  0.139597              0.0              0.0   \n",
       "12   Load CI7    7   0.07650  0.047410              0.0              0.0   \n",
       "13   Load CI9    9   0.57375  0.355578              0.0              0.0   \n",
       "14  Load CI10   10   0.06800  0.042143              0.0              0.0   \n",
       "15  Load CI12   12   5.01600  1.648679              0.0              0.0   \n",
       "16  Load CI13   13   0.03400  0.021071              0.0              0.0   \n",
       "17  Load CI14   14   0.33150  0.205445              0.0              0.0   \n",
       "\n",
       "    sn_mva  scaling  in_service  type  \n",
       "0   15.300      1.0        True  None  \n",
       "1    0.285      1.0        True  None  \n",
       "2    0.445      1.0        True  None  \n",
       "3    0.750      1.0        True  None  \n",
       "4    0.565      1.0        True  None  \n",
       "5    0.605      1.0        True  None  \n",
       "6    0.490      1.0        True  None  \n",
       "7    0.340      1.0        True  None  \n",
       "8   15.300      1.0        True  None  \n",
       "9    0.215      1.0        True  None  \n",
       "10   5.100      1.0        True  None  \n",
       "11   0.265      1.0        True  None  \n",
       "12   0.090      1.0        True  None  \n",
       "13   0.675      1.0        True  None  \n",
       "14   0.080      1.0        True  None  \n",
       "15   5.280      1.0        True  None  \n",
       "16   0.040      1.0        True  None  \n",
       "17   0.390      1.0        True  None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State space\n",
    "There are several possible state spaces that can be used to numerically represent the environment. \n",
    "\n",
    "<img src= \"figures\\observation.png\" style=width:400px;height:300px;>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Solar and demand forecast\n",
    "The state can include the solar and consumption forecast in the system. The solar forecast is generated from satellite-derived solar irradiance in central Norway. The next cell shows how to set the state space to include only the solar forecast. The attribute `env.observation_space` gives information about the state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(4,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = ActiveEnv()\n",
    "env.set_parameters({'state_space':['sun']})\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the shape of the state space is 4 because the forecast by default is 4-hour long. This can be changed by using the `set_parameters` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(24,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.set_parameters({'forecast_horizon':24})\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global solar irradiance\n",
    "The solar irradiance is assumed to be equal everywhere in the net, so there is not a unique forecast for each bus bar. However, the solar forecast is scaled up by the nominal values, so the absolute production differs from load to load.\n",
    "\n",
    "### Forecast uncertainty\n",
    "No forecasts are perfect, so the actual values should deviate from the forecasted values. The actual values are found by adding a noise term to the forecast. The noise term follows a Gaussian distribution with mean 0 and a standard deviation that is proportional to the forecast. The standard deviation in the forecasts are by default 3%. The uncertainty can be changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_parameters({'solar_std':0.1,\n",
    "                   'demand_std':0.3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bus state\n",
    "It is possible to include the bus state in the state representation. The bus state includes the voltage magnitude, voltage angle, active effect and reactive effect of each bus in the system. The bus values are found in the `res_bus` DataFrame of the pandapower net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vm_pu</th>\n",
       "      <th>va_degree</th>\n",
       "      <th>p_mw</th>\n",
       "      <th>q_mvar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-43.196502</td>\n",
       "      <td>-15.696169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994133</td>\n",
       "      <td>-6.045087</td>\n",
       "      <td>19.839000</td>\n",
       "      <td>4.637136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.977804</td>\n",
       "      <td>-6.573027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.951848</td>\n",
       "      <td>-7.414877</td>\n",
       "      <td>0.481700</td>\n",
       "      <td>0.208882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950094</td>\n",
       "      <td>-7.508922</td>\n",
       "      <td>0.411650</td>\n",
       "      <td>0.108182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.948893</td>\n",
       "      <td>-7.573678</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.182329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.947488</td>\n",
       "      <td>-7.649919</td>\n",
       "      <td>0.518050</td>\n",
       "      <td>0.137354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.952199</td>\n",
       "      <td>-7.140044</td>\n",
       "      <td>-1.423500</td>\n",
       "      <td>0.047410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.949187</td>\n",
       "      <td>-7.414180</td>\n",
       "      <td>0.556850</td>\n",
       "      <td>0.147078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.948264</td>\n",
       "      <td>-7.449484</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.355578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.947100</td>\n",
       "      <td>-7.508116</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.161264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.946916</td>\n",
       "      <td>-7.518296</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>0.082656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000146</td>\n",
       "      <td>-5.487100</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>4.693341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.995326</td>\n",
       "      <td>-5.538237</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.021071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.992553</td>\n",
       "      <td>-5.567913</td>\n",
       "      <td>0.540050</td>\n",
       "      <td>0.257713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vm_pu  va_degree       p_mw     q_mvar\n",
       "0   1.030000   0.000000 -43.196502 -15.696169\n",
       "1   0.994133  -6.045087  19.839000   4.637136\n",
       "2   0.977804  -6.573027   0.000000   0.000000\n",
       "3   0.951848  -7.414877   0.481700   0.208882\n",
       "4   0.950094  -7.508922   0.411650   0.108182\n",
       "5   0.948893  -7.573678   0.697500   0.182329\n",
       "6   0.947488  -7.649919   0.518050   0.137354\n",
       "7   0.952199  -7.140044  -1.423500   0.047410\n",
       "8   0.949187  -7.414180   0.556850   0.147078\n",
       "9   0.948264  -7.449484   0.543750   0.355578\n",
       "10  0.947100  -7.508116   0.503300   0.161264\n",
       "11  0.946916  -7.518296   0.319800   0.082656\n",
       "12  1.000146  -5.487100  20.010000   4.693341\n",
       "13  0.995326  -5.538237   0.034000   0.021071\n",
       "14  0.992553  -5.567913   0.540050   0.257713"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.powergrid.res_bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(60,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = ActiveEnv()\n",
    "env.set_parameters({'state_space':['bus']})\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the state space is 4 times the number of buses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalance state\n",
    "It is desired that the agent shifts the energy consumption, and does not alter in in absolute magnitude. The agent is therefore penalised for increasing the energy imbalance in the system. The agent must receive some information that tells it if the system is in energy imbalance on not. This is the job of the imbalance state. The imbalance state is a vector where each component is the energy imbalance of the loads in the system. Because there are 18 loads, the size of the imbalance space is 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(18,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = ActiveEnv()\n",
    "env.set_parameters({'state_space':['imbalance']})\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to only consider the total imbalance in the net. This is done by setting the parameter <i>total_imbalance</i> equal to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(1,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.set_parameters({'total_imbalance':True})\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._get_obs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action space\n",
    "\n",
    "<img src= \"figures\\N64-controller-white.jpg\" style=width:300px;height:300px;>\n",
    "\n",
    "\n",
    "There is one action for each row in load table of the network. The agent can independently change the consumption at each load in an interval of flexibility, for instance by +/- 10 %. The loads are assumed to have a constant power factor. In other words, if the active power increases by 10 %, then the reactive power also increases by 10 %. For the Cigre network, we have the action space $\\mathcal{A} = \\{a_{i}|\\;i=1,...,18\\}$, $a_{i} \\in [-1,1]$. The action is then scaled by the flexibility (0-100%) and forecasted demand, which determines the change in consumption at each load\n",
    "\n",
    "The action space is described in `env.action_space`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(18,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action space (and state space) is a `gym.spaces` object. In `ActiveEnv`, the space is a `Box`, where each dimension is bounded by an upper and lower value. The lower and upper limits are -1 and 1, and each variable can vary continuously in this interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1.], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1.], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sample()` method can be used to sample a random action uniformly from the action space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58953696,  0.660232  ,  0.69953644,  0.4281357 , -0.57135296,\n",
       "        0.5132497 ,  0.68536156,  0.5646868 , -0.10707809,  0.65083647,\n",
       "        0.27660847, -0.6086434 , -0.9253837 ,  0.37014306,  0.7565592 ,\n",
       "       -0.45291057,  0.3864012 , -0.5078616 ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the action affects the net\n",
    "`ActiveEnv` takes in the action vector $\\in \\mathbb{R^{18}}$, manipulates the `net.load` DataFrame, and solves the powerflow equation. In this example, each load increases its load as much as possible. The flexibility is 10 %.\n",
    "\n",
    "First, we create an environment instance, and look at the demand forecast. The uncertainty in the forecast is set to 0 to remove stochasticity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecasted demand:  [0.45447803]\n"
     ]
    }
   ],
   "source": [
    "env = ActiveEnv(seed=3)\n",
    "env.set_parameters({'demand_std':0})\n",
    "forecast = env.demand_forecasts[:,0]\n",
    "print('forecasted demand: ', forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the action vector of ones, which means that all loads increase their consumption as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(env.action_space.shape)\n",
    "a\n",
    "#env.step(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action interacts with the environment using the `step()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_ =env.step(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for consumption and production in the net are now updated, and one hour has passed in the episode. The consumption as a percentage of nominal values is equal at each load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.499926\n",
       "1     0.499926\n",
       "2     0.499926\n",
       "3     0.499926\n",
       "4     0.499926\n",
       "5     0.499926\n",
       "6     0.499926\n",
       "7     0.499926\n",
       "8     0.499926\n",
       "9     0.499926\n",
       "10    0.499926\n",
       "11    0.499926\n",
       "12    0.499926\n",
       "13    0.499926\n",
       "14    0.499926\n",
       "15    0.499926\n",
       "16    0.499926\n",
       "17    0.499926\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumption = env.powergrid.res_load['p_mw']/env.powergrid.load['sn_mva']\n",
    "consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The consumption is 10 % higher than the forecast at every load because the flexibility is 10 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.1\n",
       "1     1.1\n",
       "2     1.1\n",
       "3     1.1\n",
       "4     1.1\n",
       "5     1.1\n",
       "6     1.1\n",
       "7     1.1\n",
       "8     1.1\n",
       "9     1.1\n",
       "10    1.1\n",
       "11    1.1\n",
       "12    1.1\n",
       "13    1.1\n",
       "14    1.1\n",
       "15    1.1\n",
       "16    1.1\n",
       "17    1.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumption/forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller action space\n",
    "18 free variables in an action space is quite large. It is possible to set a global action that modifies all the loads in the interval of flexibility. This is done shown in the cell below. Note that the change is a percentage change in consumption and the loads have different nominal consumption levels. Therefore, the absolute power change varies from load to load. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_parameters({'one_action':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the action space is now 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(1,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewards\n",
    "Rewards are fundamental to all reinforcement learning algorithms. In this case, it is simpler to talk about costs, rather than rewards. The reward is defined as the negative of the cost, so maximising the reward is the same as minimising the cost. Different reward terms can be specified in the `ActiveEnv` class.\n",
    "<img src= \"figures\\reward.png\" style=width:400px;height:400px;>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voltage cost\n",
    "The goal of the agent is to reduce the number of current and voltage violations in the net. Therefore, one must define what a violation is. There is a voltage violation in the net if the voltage magnitude somewhere steps out of the safety bound. The safety bounds can be specified and are by default 0.95 - 1.05 pu. Currently, the voltage cost for one bus is proportional to the voltage violation, as shown in the figure below. The total voltage cost is found by summing over all bus bars.  \n",
    "\n",
    "<img src= \"figures\\voltage_cost.png\" style=width:500px;height:370px;>\n",
    "\n",
    "There is a weight that scales total voltage cost, whose default value is 1. The next cell shows how to only include the voltage in the reward calculation and change the voltage weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ActiveEnv(seed=3)\n",
    "env.set_parameters({'reward_terms':['voltage'],\n",
    "                   'voltage_weight':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower and upper limit can be changed by using the `set_parameters()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_parameters({'v_lower':0.9,\n",
    "                   'v_upper':1.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current cost\n",
    "Similarly, there is a current violation in a line if the current exceeds a capacity threshold, which by default is set to 90%. The cost is proportional to the violation in the line, and the total cost is found by summing over all lines. It might be more appropriate to have a non-linear relation, so that one large violation is punished more than several small violations.\n",
    "\n",
    "<img src= \"figures\\current_cost.png\" style=width:500px;height:370px;>\n",
    "\n",
    "There is also a weight for the current cost, which is 0.01 by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ActiveEnv(seed=3)\n",
    "env.set_parameters({'reward_terms':['current'],\n",
    "                   'current_weight':0.05})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance cost\n",
    "The imbalance cost penalises a large energy imbalance. The agent should ideally increase power consumption during peak solar production and less during peak demand. The imbalance cost is there to incentives the agent to shift the energy consumption. There are two variations of the imbalance cost:\n",
    "\n",
    "- <b>Absolute energy imbalance:</b> The agent is penalised proportionally to the energy imbalance over the last 24 hours.\n",
    "\n",
    "\n",
    "- <b>Increasing energy imbalance:</b> The agent is penalised proportionally to the increase in absolute energy imbalance. For instance, consider a scenario where the imbalance is +20 MWh, and that it increases to +25 MWh and after the agent has performed its action. The imbalance cost is then $(25 - 20)*\\texttt{imbalance weight}$. This cost becomes negative when the imbalance decreases, and is the only time the agent can get a positive reward\n",
    "\n",
    "\n",
    "The default version is the <u>absolute energy imbalance</u> . The next cell shows how to switch to the imbalance change, and how to alter the imbalance weight, which by default is $10e-5$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ActiveEnv(seed=3)\n",
    "env.set_parameters({'reward_terms':['imbalance'],\n",
    "                   'imbalance_change':True,\n",
    "                   'imbalance_weight':10e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation cost\n",
    "Flexibility is unfortunately not a free resource. Currently, the activation cost is proportional to the absolute power change resulting for the agent's action, with a constant price. A more realistic environment should include the cost in the state space, so the agent can learn that it is expensive to change the consumptions when the price is high. The default activation weight is 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ActiveEnv(seed=3)\n",
    "env.set_parameters({'reward_terms':['activation'],\n",
    "                   'activation_weight':10e-3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total cost\n",
    "<b>The total cost is found by summing the voltage, current, imbalance and activation cost<b/>\n",
    "    \n",
    "<img src= \"figures\\total_cost.png\" style=width:800px;height:130px;>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a reinforcement agent with stable-baselines\n",
    "Stable-baselines simplifies reinforcement learning in Python, just like sklearn simplifies supervised learning. You can easily test different reinforcement algorithms and policies. Most of the RL algorithms support multiprocessing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.008776205  |\n",
      "| clipfrac           | 0.13085938   |\n",
      "| explained_variance | 0.00713      |\n",
      "| fps                | 46           |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 25.545404    |\n",
      "| policy_loss        | -0.036377445 |\n",
      "| serial_timesteps   | 128          |\n",
      "| time_elapsed       | 0            |\n",
      "| total_timesteps    | 128          |\n",
      "| value_loss         | 3.8982704    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0030996634 |\n",
      "| clipfrac           | 0.033203125  |\n",
      "| explained_variance | 0.0295       |\n",
      "| fps                | 63           |\n",
      "| n_updates          | 2            |\n",
      "| policy_entropy     | 25.555183    |\n",
      "| policy_loss        | -0.017375557 |\n",
      "| serial_timesteps   | 256          |\n",
      "| time_elapsed       | 2.75         |\n",
      "| total_timesteps    | 256          |\n",
      "| value_loss         | 28.427862    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0018272824  |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| explained_variance | 0.0312        |\n",
      "| fps                | 61            |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 25.554373     |\n",
      "| policy_loss        | -0.0038009733 |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 4.75          |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 111.62187     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014519556 |\n",
      "| clipfrac           | 0.001953125  |\n",
      "| explained_variance | 0.0549       |\n",
      "| fps                | 64           |\n",
      "| n_updates          | 4            |\n",
      "| policy_entropy     | 25.5507      |\n",
      "| policy_loss        | -0.006698979 |\n",
      "| serial_timesteps   | 512          |\n",
      "| time_elapsed       | 6.83         |\n",
      "| total_timesteps    | 512          |\n",
      "| value_loss         | 29.508547    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.005807397  |\n",
      "| clipfrac           | 0.087890625  |\n",
      "| explained_variance | 0.151        |\n",
      "| fps                | 59           |\n",
      "| n_updates          | 5            |\n",
      "| policy_entropy     | 25.5476      |\n",
      "| policy_loss        | -0.023377838 |\n",
      "| serial_timesteps   | 640          |\n",
      "| time_elapsed       | 8.83         |\n",
      "| total_timesteps    | 640          |\n",
      "| value_loss         | 5.0111165    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0033107824 |\n",
      "| clipfrac           | 0.037109375  |\n",
      "| explained_variance | -0.152       |\n",
      "| fps                | 63           |\n",
      "| n_updates          | 6            |\n",
      "| policy_entropy     | 25.548231    |\n",
      "| policy_loss        | -0.013940289 |\n",
      "| serial_timesteps   | 768          |\n",
      "| time_elapsed       | 11           |\n",
      "| total_timesteps    | 768          |\n",
      "| value_loss         | 0.6069521    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0062571233 |\n",
      "| clipfrac           | 0.09765625   |\n",
      "| explained_variance | 0.0498       |\n",
      "| fps                | 64           |\n",
      "| n_updates          | 7            |\n",
      "| policy_entropy     | 25.547384    |\n",
      "| policy_loss        | -0.02822937  |\n",
      "| serial_timesteps   | 896          |\n",
      "| time_elapsed       | 13           |\n",
      "| total_timesteps    | 896          |\n",
      "| value_loss         | 3.097296     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x29997404898>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from gym_power.envs.active_network_env import ActiveEnv\n",
    "\n",
    "env = ActiveEnv()\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO2(MlpPolicy, env, verbose=2)\n",
    "model.learn(total_timesteps=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models\\ppo_agent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the trained agent play:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "for i in range(10):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl_env] *",
   "language": "python",
   "name": "conda-env-rl_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
