\documentclass[class=book, crop=false]{standalone}
\usepackage[subpreambles=true]{standalone}
\usepackage[utf8]{inputenc}
\usepackage{import}
\usepackage[ruled,vlined]{algorithm2e}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1.2in]{geometry}
\usepackage[sorting = none,
            doi = true  %lesedato for url-adresse
            ]{biblatex} %none gir bibliografi i sitert rekkef√∏lge
\addbibresource{reference.bib}
\usepackage{csquotes}
\usepackage{pgfplots}
\usepackage{pgfplotstable}

\pgfplotsset{compat=1.15}

\begin{document}
\chapter{Discussion}
\section{Nominal values for consumption and production}
The action of the reinforcement agent determines the percentage change in demand at each load in the interval $[-f,f]$, where $f$ is the flexibility of demand. Naturally, the load is varying a lot throughout a day, but the nominal demand also vary a lot from bus to bus. Figure \ref{fig:discussion:nominal_load} shows the values for nominal apparent power at each bus bar in the power system, as predefined in \texttt{pandapower}.

\begin{figure}[ht]
    \center
\includegraphics[height=8cm, width=12cm]{figures/nominal_load.png}
    \caption[size = 9]{Bar plot of the nominal apparent power at each bus in the CIGRE network}
    \label{fig:discussion:nominal_load}
\end{figure}

Bus 1 and 12 clearly stand out, and account for nearly 90 \% of the total system demand. For simplicity, they will be referred to as the dominant buses due their large demand. Note that there is no solar power connected to them. Because each action variable is scaled up by the nominal load, it is clear that action +1 for the dominant buses has a much larger impact in terms of absolute power change than it has on the rest of the buses. As shown in figure \ref{fig:discussion:cigre_network_dominant}, The dominant buses are placed in the top of each feeder 1 and feeder 2, connected to each their 220/22 kV transformer. 

\begin{figure}[ht]
    \center
    \includegraphics[height=14cm, width=13.5cm]{figures/cigre_network_dominant.png}
    \caption[size = 9]{CIGRE network with solar and wind power that is used in the reinforcement learning algorithm \cite{cigre}. The dominant buses account for approximately 90 \% of the power consumption in the grid}
    \label{fig:discussion:cigre_network_dominant}
\end{figure}
It might seem troubling that these buses have a much larger nominal values. However, because they are placed next to the grid, they do not affect the line current in the rest of the system much. For instance, if the load at bus 1 is doubled, the current through the transformer approximately doubles to supply the demand. Naturally, this could be very critical for the transformer, but it has a small effect on the line currents in the power system, because the rest of the loads still draw the same amount of power from the grid. The line current effect of changing the demand at bus 1 and 12 are not that decisive as one first might think, due to their position close to the external grid. On the other hand, they can greatly affect the voltage magnitudes in the grid. Figure \ref{fig:discussion:double_large_load} illustrates the effect increasing the demand at the dominant buses has on the rest of the buses. The predefined demand values are used for solving the power flow equations in situation A, while they are doubled for the dominant buses (1 and 12) in situation B.

\begin{figure}[h]
    \center
\includegraphics[height=8cm, width=12cm]{figures/double_large_load.png}
    \caption[size = 9]{Bar plot for each of the buses showing their voltage magnitude in nominal operation (A) and after the demand at bus 1 and 12 in \ref{fig:discussion:cigre_network_dominant} is doubled (B). Note that the second axis is truncated}
    \label{fig:discussion:double_large_load}
\end{figure}
The dominant buses serve as the starting point for the voltage magnitudes because they are at the beginning of the two feeders. This is true because there are only PQ-buses in the system and no voltage regulating units. The voltage is static at the external grid, and gradually falls as we move down the feeders in periods of peak demand. The voltage magnitude at bus 1 is reduced when it doubles its demand, which in turn propagates down the feeder and affects all buses in the feeder. The difference in voltage magnitude at each bus before and after the demand increase is almost linear. The reinforcement agent is not allowed to double the demand in the reinforcement algorithm, but figure \ref{fig:discussion:double_large_load} illustrates the decisive effect of the dominant buses in terms of voltage magnitudes.

\begin{figure}[h]
    \center
\includegraphics[height=8cm, width=12cm]{figures/voltage_impact.png}
    \caption[size = 9]{Box plot for each bus bar showing the voltage impact for a flexibility of demand ranging from -20 to + 20 \% in an hour of peak demand}
    \label{fig:discussion:voltage_impact}
\end{figure}

A measure of impact is needed to systematically investigate the effects of changing the demand at a bus. Let the voltage and current impact of a bus respectively be defined as the sum of the changes in voltage and current loading in the net when modifying the demand at that bus by a certain percent. For instance, the voltage impact of bus 1 shown in figure \ref{fig:discussion:double_large_load} is the voltage difference of scenario A and B, summed over all buses. The same can be done for the current impact, which is the difference in current loading (between 0\% and 100 \%) summed over all lines. Note that the rest of the buses are left unchanged when calculating the impact. The impact of a bus will be discussed the two critical periods of the day, namely peak solar production and peak demand. For peak solar production, the average demand and maximum solar production at 12 am are used to define the values for consumption and production. For peak demand, the average solar production and maximum demand at 7 pm is used. 


Figure \ref{fig:discussion:voltage_impact} plots the voltage impact during peak demand for each bus where the demand change ranges from -20 to +20 \%. The lower part of the box plots correspond to increasing the demand by 20 \%, since increasing the consumption in peak demand lowers the voltage magnitudes in the grid. As already discussed, bus 1 have a large voltage impact, because it is at the top of feeder 1. 


Figure \ref{fig:discussion:current_impact} plots the current loading impact in peak demand hours for the buses in the net. The lower part of the box plots corresponds to decreasing the consumption, since less current is needed to supply the demand. The buses with highest current impact (5,6,9,10) are all located far down in feeder 1. A change in demand at them has consequences for several lines, because the current they draw must travel through the lines in the top of the feeder. As discussed, the current loading impact is low for the dominant buses (1 and 12), despite the fact that they account for nearly 90 \% of the consumption in the system. 


\begin{figure}[h]
    \center
\includegraphics[height=8cm, width=12cm]{figures/current_impact.png}
    \caption[size = 9]{Box plot for each bus bar showing the current importance during peak demand for a demand change ranging from -20 to + 20 \%}
    \label{fig:discussion:current_impact}
\end{figure}

So far the impacts of the buses have been investigated in hours of peak demand. A similar simulation in an hour of peak solar production can be done to show the impact of the buses in the second critical period. The impact relation between the buses in peak solar hours is similar to the peak demand period. In other words, if a bus has a large impact in peak demand, it also has large impact during peak solar production compared to the other buses. However, the magnitude differs a lot for the two critical periods. Figure \ref{fig:discussion:current_impact_demand_solar} plots the current loading impact factor for each bus when the demand is increased by 10\% in hours of peak demand and peak solar production. The current impacts in peak solar production are lower in all cases, except for bus 1. Similarly, figure     \ref{fig:discussion:voltage_impact_demand_solar} show the difference in voltage impact during peak demand and peak solar production. The impacts differ because the power consumption generally is lower during peak solar production. The mean demand in the hour of maximum solar production (12 am) less than half of the max demand value at 7 pm. Consequently, changing the demand by 10 \% at 12 am results in a absolute power change that is about half the change during peak demand. The agent simply has less muscles during peak solar production, because it is physically impossible to affect the grid as much as in the afternoon during peak demand. This can explain why the trained agent performs well i periods of peak demand and poorly in periods of peak solar production.

\begin{figure}[h]
    \center
\includegraphics[height=8cm, width=12cm]{figures/current_impact_demand_solar.png}
    \caption[size = 9]{Current impact of all the buses in an hour of peak demand and peak solar production. The demand is changed by 10 \%}
    \label{fig:discussion:current_impact_demand_solar}
\end{figure}

\begin{figure}[h]
    \center
\includegraphics[height=8cm, width=12cm]{figures/voltage_impact_demand_solar.png}
    \caption[size = 9]{Voltage impact of all the buses in an hour of peak demand and peak solar production. The demand is changed by 10 \%}
    \label{fig:discussion:voltage_impact_demand_solar}
\end{figure}

\section{Performance of the trained agent}
The results from section \ref{section:result:config1} show that the trained agent is able to reduce the number of safety violation by 10\%. However, the trained agent is only able to reduce violations of voltage safety margins, not current violations. In fact, it increases the number of current violations by 18 \%. Still, there are large differences in terms of the quantity and magnitude of the current and voltage safety violations. There are almost 7 times more voltage violations than current violations. This is of course dependent on the voltage bounds that are used for defining the voltage cost. In this case the voltage bounds are chosen to be 0.95 and 1.05 pu. Although there are many more voltage violations in a normal day, the average current violation is more severe. Specifically, the mean current cost is almost 5 times greater than the mean voltage cost. The nature of the transmission in terms of violations is therefore: the current violation are sparse and severe, while the voltage violations are numerous and faint. 

Why is the trained agent better at avoiding voltage violation than current violations? A possible reason is that the agent is penalised more for voltage violations on average. The total voltage costs is 40 \% greater than the total current cost, because they are more frequent. It is logical that the agent learns a behaviour that reduces the most punishing term, namely the voltage cost. As stated in section \ref{section:config1:current_violations}, the trained agent only learned the appropriate behaviour in periods of peak demand, i.e reducing the demand so that less power need to be imported from the grid.

The agent was worsening the situation in periods of peak solar production. The desired behaviour in such a situation is to increase the demand, so that less excess solar power needs to be exported to the grid. Consequently, the trained agent decreases the demand in periods of peak solar production, since the number of line overload increases. It is possible that the learned behaviour simply is to decrease the demand at all times, especially when considering that the energy imbalance in the system is negative, as shown in figure \ref{fig:results:configuration1_energy_imbalance}. Figure \ref{fig:discussion:config1_action_hour} shows the mean action taken by the agent throughout a the day in the 500 episode simulation. The error band is a 95 \% confidence interval. The pattern of the actions is as desired, because the it goes up during peak solar producing and down during peak demand in the afternoon. However, the change in demand during peak demand is still negative. The action signal seem to have a negative bias. It is also worth noting that the mean action is quite low in absolute magnitude. In other words, the agent is not synchronising the buses such that the entire available flexibility in the system used.

\begin{figure}[h]
    \center
\includegraphics[height=8cm, width=12cm]{figures/config1_action_hour.png}
    \caption[size = 9]{Hourly mean values for the change in demand at the buses in the net, as determined by the trained reinforcement agent. The error bars are a confidence interval of 95\%}
    \label{fig:discussion:config1_action_hour}
\end{figure}

Figure \ref{fig:discussion:config1_action_bus} shows mean values for demand change throughout a day for each bus.  The buses 1,6,8 and 9 are on average negative in every hour, i.e the agent always reduces the consumption. As discussed, the different buses have different voltage and load current impact, and it is interesting to see whether there is a relationship between actions and load current/voltage impact of the buses. First it can be noted that bus 1 (top left corner) which have the largest voltage impact in hours of peak demand mainly is negative in an average day. This can suggest that the trained agent have learned that lowering the consumption is beneficial in peak demand hours, and therefore has a strong negative bias that pulls the demand change to negative values throughout the day. 

\begin{figure}[h]
    \center
\includegraphics[height=13cm, width=12cm]{figures/config1_action_bus.png}
    \caption[size = 9]{Hourly mean values for the change in demand in the net for each bus, as determined by the trained reinforcement agent. The error bars are a confidence interval of 95\%}
    \label{fig:discussion:config1_action_bus}
\end{figure}


\section{Solar power production}
The nominal solar production level predefined in the network is scaled up by a factor of 40. This is done to challenge the grid by increasing the number of current and voltage violations in hours of peak solar production. The nominal values for solar production and consumption at the solar producing buses are presented in figure \ref{fig:discussion:nominal_sgen}


\begin{figure}[h]
    \center
\includegraphics[height=8cm, width=12cm]{figures/nominal_sgen.png}
    \caption[size = 9]{Bar plot of the nominal apparent power consumption and solar production at solar producing buses in the grid}
    \label{fig:discussion:nominal_sgen}
\end{figure}




\section{State representation}
There are many different ways of constructing the state space in the reinforcement agent. In section \ref{section:problem:state_space} several candidates for the state space were introduced, such as the the bus space. The bus space consists of the active power $P$, reactive power $Q$, voltage magnitude $|U|$ and phase angle $\delta$ for all the buses in the system. It was not included in the state space of the trained reinforcement agent. A reason for this is that the current bus state tells nothing relevant about the future. Naturally, there is a correlation between the bus state and the subsequent state. For instance, during peak demand in the afternoon, the demand between two hours are highly correlated, which in turns determines the bus states. However, this information can be found in the demand forecasts. In some sense, the bus state in the current time step is redundant. During peak solar production, we can have an hour with heavy production from solar units, but in the next hour the forecasts says that there will be cloudy. It is not possible to predict the clouds from the bus state. The predictive information is hidden in the forecast. Of course, the forecasts can be used to calculate the predicted bus state, which can be helpful information for the agent. However, this will slow down the training process, because the power flows equation must be solved, possibly several times if many future bus states are going to be estimated. 
- Why several hour forecast?
- Include flexibility, price of flexibility, bus-wise features. 


\section{Reward function}
The reward function is designed to penalise violations of safety margins in the grid. Specifically, current overloads and violations of voltage safety margin are the factors that are used to calculate the reward signal. There are however two transformers in the grid, that also should be included in the reward functions. Transformers are not fireproof. \texttt{pandapower} has a result table for the transformer, that easily could be integrated in the reward function. This would make the current impact of the dominant buses greater as well. 

The reward terms for current and voltage respectively sum over every line and bus bar. By this definition it is mathematically possible that the magnitude of a current violation in an individual line increases, but the overall penalty is less. For instance, consider the following scenario. Say that the current loading in three lines are 105\%, 104\% and 104\%. With a upper current loading limit of 90 \%, the current cost would be 15 + 14 + 14 = 43. Imagine that the reinforcement learning agent takes an action and that the resulting current loading in the three lines are 115 \%, 97 \% and 97\%. The resulting current cost would then be 25 + 7 + 7 = 39, which  is lower than the original one. According to the reward function, the second scenario is better, although an individual line is pushed further out of the safety margin, possibly damaging it severely. This is mathematically possible, but the question is whether this is physically realistic. The trained reinforcement agent controls the change in consumption in at the buses in the net. Referring the the imagined scenario above, two of the tree lines reduce their current loading, and the way to achieve this in peak demand is by reducing the consumption at some buses. This would not affect the power drawn by the other buses or in any way cause larger current in any other line. On the contrary, decreasing the demand in peak demand would increase voltage magnitudes in the grid, which in turn would reduce the line current ($P = UI$). Consequently, it is not physically realistic that the described scenario happens in the reinforcement learning setup used in this thesis.

The same scenario is mathematically possible with voltage violations as well. Again, it is physically unrealistic that it would happen, because if the voltage magnitude at a bus increases, it will push up the voltage magnitudes in the rest of the buses.


\section{Energy imbalance}
Figure \ref{fig:discussion:config1_imbalance_reward} shows the distribution of imbalance reward given to the trained agent in the 500 episode test simulation. The mean imbalance reward is -0.02, which is smaller than both the mean current and voltage cost. However, there is a non-zero imbalance reward at every time step, in contrast to current and voltage reward. The current and voltage reward is only non-zero when there is a violation in the grid, while a imbalance reward is given in every hour. Therefore, the imbalance cost is by far the most dominant factor in the total reward given to the agent. The total imbalance cost in the 500 episode simulation is 2039, over four times as large as the current and voltage costs combined. Naturally, this works against the original goal of reducing the number of safety violations in the grid. How is the agent suppose learn how to reduce the number of safety violations, when it is penalised much more for increasing the energy imbalance in the system? Why would it not simply learn to reduce the total energy imbalance? The trivial solution to this is to never change the demand in the grid, i.e all actions are 0. Still, this is not the behaviour we observe, we see that it simply tends to decrease the energy imbalance in the system. The energy imbalance term gives a positive reward if the absolute energy imbalance in the system moves closer to 0. Thus, it is not penalised for the absolute magnitude of the energy imbalance. The energy imbalance can be considered a poor and misleading term in the reward function of used in the reinforcement learning algorithm.   

\begin{figure}[h]
    \center
\includegraphics[height=8cm, width=12cm]{figures/config1_imbalance_reward.png}
    \caption[size = 9]{Violin plot of the imbalance reward given to the trained agent in a 500 episode simulation}
    \label{fig:discussion:config1_imbalance_reward}
\end{figure}

\section{Suitable reinforcement learning task}

\end{document}