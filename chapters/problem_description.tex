\documentclass[class=book, crop=false]{standalone}
\usepackage[subpreambles=true]{standalone}
\usepackage{import}
\usepackage[ruled,vlined]{algorithm2e}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1.2in]{geometry}
\usepackage[sorting = none,
            doi = true  %lesedato for url-adresse
            ]{biblatex} %none gir bibliografi i sitert rekkef√∏lge
\addbibresource{reference.bib}
\usepackage{csquotes}
\usepackage{pgfplots}
\pgfplotsset{compat=1.15}

\begin{document}
\section{Problem description}
Solar power production occurs during day-time and is, not surprisingly, controlled by the sun. Figure ?? shows a typical solar profile for a day. As photovoltaic modules become common in residential areas, they will grow to a size where they produce a significant amount of power that must be transported out on the grid. A consequence of this can can be that safety bounds for both voltage and line capacity are violated. A strategy for avoiding is called demand response. Albadi and El-Saadany give the following definition of demand response.\cite{demand_response_definition}

\begin{displayquote}
Demand response can be defined as the changes in electricity usage by end-use customers from their normal consumption patterns in response to changes in the price of electricity over time. Further, DR can be also defined as the incentive payments designed to induce lower electricity use at times of high wholesale market prices or when system reliability is jeopardised. DR includes all intentional electricity consumption pattern modifications by end-use customers that are intended to alter the timing, level of
instantaneous demand, or total electricity consumption.
\end{displayquote}


The idea is to modify the demand of electric power to follow the production profile of distributed energy resources (DER), such as solar power. The specific setup in this thesis is based on several assumptions for a hypothetical future power grid. The electrical power grid used is constructed by the International Council on Large Electric Systems (CIGRE) as a benchmark network that can be used for analysis of DER integration\cite{cigre}. The network is predefined in pandapower and can be defined with different renewable energy sources connected at different buses. The grid used is visualised in figure \ref{fig:problem:cigre_network}. 

\begin{figure}[H]
    \includegraphics[height=14cm, width=13.5cm]{figures/cigre_network_mv_der.png}
    \caption[size = 9]{CIGRE network with solar and wind power that is used in the reinforcement learning algorithm}
    \label{fig:problem:cigre_network}
\end{figure}
The left-most feeder has several solar producing units connected and wind power connected to bus 7. The time resolution in this task is chosen to be hourly. In other words, the demand and solar production at every bus is updated every hour, and assumed constant in between hours. The demand profile is generated using \textit{enlopy}, a python toolkit for energy demand time series\cite{enlopy}. The demand signal is generated based on data of the energy consumption of private households. A data set with solar irradiance in Konongo, Ghana is used as input to define the production of solar power. The signal of solar production and power demand is assumed equal at all buses and scaled up based on nominal values of the loads at each bus. This reduces the state space, as there is no need for a unique demand forecast for all the loads.  For simplicity, the power factor is assumed constant at every bus, meaning the reactive power at each load is a percentage of the active power at all times. The values of the solar production are intentionally amplified so that the safety margins in the grid frequently are violated if no actions are taken.   

All loads have an hourly forecast of energy consumption that is used to update the active and reactive powers at every timestep It is assumed that the loads at all buses have some flexibility, say 10 \% of the actual demand, that can be centrally controlled at every hour. 

\section{State space}
It is not obvious how to design the state space for the agent. This section presents several spaces that could be useful for the reinforcement algorithm. Let $\mathcal{S}_{1} \in \mathbb{R}^{k}$ be space of the forecasted total solar production in the grid \textit{k} hours into the future . This gives the agent information about the coming solar production in the power marked that can be used for finding strategies. For instance, consider a situation with a high production of solar power that is overreaching the capacity in the power lines. If the agent sees that there is a dip in solar production in the next hour due to clouds, it can increase the local demand at solar producing, to relieve the overloaded power lines. It can then safely decrease the demand the next hour, since the sun is blocked by the clouds. This is an example of a desired behaviour that the agent ideally should find. 


Let $\mathcal{S}_{1} \in \mathbb{R}^{k}$ be the space of the forecasted total demand in the grid $k$ hours into the future. In other words, it is the 
- 24 hour solar forecast at every static generator (bus with solar panel). Same for all panels, solar irradiance is assumed constant in the network
- 24 hour power demand forecast at every bus load
- |V|, $\delta$, P, Q at every bus

The last piece should be a vector that ensures that the consumption at a load merely is shifted and not altered in absolute magnitude. In other words, a state that contains information about the energy deviation for a load. For instance, if a load modulated by -1 MW for an hour, the agent must increase the load by 1 MW some time not far into the future. Gemine et al did this by making a commitment when a load is modulated. When a load is modulated, it follows a predefined modulation curve for $T_{d}$ time steps (for instance 4 steps). The modulation signal is constructed so that is sums to zero of over the time period $T_{d}$, which garantues that the total energy consumption of the load is constant. This could be a possible approach for a reinforcement learning algorithm aswell. The last state vector could indicate in what modulation step a load is at. For instance, if the modulation started at $t_{0}$ for a load and the current time step is $t_{0} + 3$, then the load component of this vector is 3. The agent is then always fed with a signal that tells it the commitment stage of that load. The desired action of the agent at a time step in the commitment period will simply be ignored. This can of course confuse the agent, because it thinks that its action is performed, but this is not always the case. Hopefully the agent will pick up on this through the commitment state vector. I do however doubt this approach, as it seems a bit too complicated for the agent to learn. It already has a very large state space, and I don't think that it will be able learn this dynamics. We will see.



\end{document}